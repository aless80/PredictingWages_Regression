{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study: Predicting Wages\n",
    "## Linear regression using [sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) or [patsy]([Patsy](https://patsy.readthedocs.io/en/latest/#) + [statsmodels](http://www.statsmodels.org/stable/index.html#), and cross correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>female</th>\n",
       "      <th>cg</th>\n",
       "      <th>sc</th>\n",
       "      <th>mw</th>\n",
       "      <th>so</th>\n",
       "      <th>we</th>\n",
       "      <th>ne</th>\n",
       "      <th>exp1</th>\n",
       "      <th>exp2</th>\n",
       "      <th>exp3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3835.000000</td>\n",
       "      <td>3835.000000</td>\n",
       "      <td>3835.000000</td>\n",
       "      <td>3835.000000</td>\n",
       "      <td>3835.000000</td>\n",
       "      <td>3835.000000</td>\n",
       "      <td>3835.000000</td>\n",
       "      <td>3835.000000</td>\n",
       "      <td>3835.000000</td>\n",
       "      <td>3835.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.417992</td>\n",
       "      <td>0.376271</td>\n",
       "      <td>0.323859</td>\n",
       "      <td>0.287614</td>\n",
       "      <td>0.243546</td>\n",
       "      <td>0.211734</td>\n",
       "      <td>0.257106</td>\n",
       "      <td>13.353194</td>\n",
       "      <td>2.529267</td>\n",
       "      <td>5.812103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.493293</td>\n",
       "      <td>0.484513</td>\n",
       "      <td>0.468008</td>\n",
       "      <td>0.452709</td>\n",
       "      <td>0.429278</td>\n",
       "      <td>0.408591</td>\n",
       "      <td>0.437095</td>\n",
       "      <td>8.639348</td>\n",
       "      <td>2.910554</td>\n",
       "      <td>9.033207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.216000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.210000</td>\n",
       "      <td>1.331000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>3.802500</td>\n",
       "      <td>7.414875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>42.875000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            female           cg           sc           mw           so  \\\n",
       "count  3835.000000  3835.000000  3835.000000  3835.000000  3835.000000   \n",
       "mean      0.417992     0.376271     0.323859     0.287614     0.243546   \n",
       "std       0.493293     0.484513     0.468008     0.452709     0.429278   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     1.000000     1.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "                we           ne         exp1         exp2         exp3  \n",
       "count  3835.000000  3835.000000  3835.000000  3835.000000  3835.000000  \n",
       "mean      0.211734     0.257106    13.353194     2.529267     5.812103  \n",
       "std       0.408591     0.437095     8.639348     2.910554     9.033207  \n",
       "min       0.000000     0.000000     2.000000     0.040000     0.008000  \n",
       "25%       0.000000     0.000000     6.000000     0.360000     0.216000  \n",
       "50%       0.000000     0.000000    11.000000     1.210000     1.331000  \n",
       "75%       0.000000     1.000000    19.500000     3.802500     7.414875  \n",
       "max       1.000000     1.000000    35.000000    12.250000    42.875000  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data. I previously copied the data in the .Rdata file to data.csv\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('data.csv', index_col=False, header=0)\n",
    "y = data.wage.values\n",
    "y = y[:, None]\t\t\t\t\t#needs to be 2d for LinearRegression\n",
    "data.drop(['hsg','wage'],axis=1,inplace=True)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>female</th>\n",
       "      <th>cg</th>\n",
       "      <th>sc</th>\n",
       "      <th>mw</th>\n",
       "      <th>so</th>\n",
       "      <th>we</th>\n",
       "      <th>ne</th>\n",
       "      <th>exp1</th>\n",
       "      <th>exp2</th>\n",
       "      <th>exp3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [female, cg, sc, mw, so, we, ne, exp1, exp2, exp3]\n",
       "Index: []"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "pearsonr(data['ne'],data.mw)\n",
    "data[(data['ne']==1) & (data['we']==1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic model with 10 features: linear and Quadratic specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression on basic model: p=11, R2=0.095, R2adj=0.09, MSEadj=165.25\n"
     ]
    }
   ],
   "source": [
    "###  Linear and Quadratic specifications\n",
    "###  Basic model with 10 features\n",
    "x = data.values\n",
    "\n",
    "fmla_basic = LinearRegression(fit_intercept=True)\n",
    "fmla_basic.fit(x,y)\n",
    "\n",
    "#Grab the results of the linear fit\n",
    "n_basic = y.size\n",
    "p_basic = fmla_basic.coef_.size+fmla_basic.intercept_.size\n",
    "R2_basic = fmla_basic.score(x,y)\n",
    "R2adj_basic = 1 - (1-R2_basic)*(n_basic-1)/(n_basic-p_basic-1)\n",
    "MSEadj_basic = (n_basic/(n_basic-p_basic))*((fmla_basic.predict(x) - y)**2).mean() \t#165.68 in R\n",
    "\n",
    "print(\"Regression on basic model: p=%.0f, R2=%.3f, R2adj=%.2f, MSEadj=%.2f\" %(p_basic,R2_basic,R2adj_basic,MSEadj_basic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Flexible model with 33 features: linear and quadratic specifications plus their two-way interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3835, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Repeat the linear fit using the same controls plus their interactions\n",
    "xint=x.copy()\n",
    "xint=np.delete(xint,0,axis=1)\n",
    "xint.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate columns with interactions of controls\n",
    "xint=x.copy()\n",
    "xint=np.delete(xint,0,axis=1)\n",
    "for i in range(1,x.shape[1]):\n",
    "\tfor j in range(i+1,x.shape[1]):\n",
    "\t\tinter = x[:,i]*x[:,j]\n",
    "\t\tinter = inter[:,None]\n",
    "\t\txint = np.hstack((xint, inter))\n",
    "female = data.iloc[:,0]; female = female[:, None]\n",
    "xint=np.hstack((female,xint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression on flexible model: p=47, R2=0.10, R2adj=0.09, MSEadj=163.70\n"
     ]
    }
   ],
   "source": [
    "###  Flexible model with 38 features\n",
    "fmla_flex = LinearRegression(fit_intercept=True)\n",
    "fmla_flex.fit(xint,y)\n",
    "\n",
    "#NB: 5 coefficients are not defined in the R code: \n",
    "#    sc:cg, mw:so, mw:we, so:we, exp1:exp2\n",
    "\n",
    "n_flex = y.size\n",
    "p_flex = fmla_flex.coef_.size+fmla_flex.intercept_.size\n",
    "R2_flex = fmla_flex.score(xint,y)\n",
    "R2adj_flex = 1 - (1-R2_flex)*(n_flex-1)/(n_flex-p_flex-1)\n",
    "MSEadj_flex = (n_flex/(n_flex-p_flex))*((fmla_flex.predict(xint) - y)**2).mean() \t#165.12 in R\n",
    "print(\"Regression on flexible model: p=%.0f, R2=%.2f, R2adj=%.2f, MSEadj=%.2f\" %(p_flex,R2_flex,R2adj_flex,MSEadj_flex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression on basic model:    p=11, R2=0.10, MSEadj=165.25\n",
      "Regression on flexible model: p=47, R2=0.10, MSEadj=163.70\n"
     ]
    }
   ],
   "source": [
    "### Summary: linear regression on basic and flexible models\n",
    "print(\"Regression on basic model:    p=%.0f, R2=%.2f, MSEadj=%.2f\" %(p_basic,R2_basic,MSEadj_basic))\n",
    "print(\"Regression on flexible model: p=%.0f, R2=%.2f, MSEadj=%.2f\" %(p_flex,R2_flex,MSEadj_flex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using cross correlation\n",
    "### Basic model with 10 features: linear and quadratic specifications with Sample Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amarin/.local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((767, 10), (767, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Use cross validation on the data\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,  test_size=0.8, random_state=0)\n",
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression on basic model using cross validation: p=11, R2=0.08, MSE=189.35\n"
     ]
    }
   ],
   "source": [
    "###  Linear and Quadratic specifications\n",
    "###  Basic model with 10 features\n",
    "fmla_cvbasic = LinearRegression(fit_intercept=True)\n",
    "fmla_cvbasic.fit(x_train,y_train)\n",
    "yhat = fmla_cvbasic.predict(x_test)\n",
    "\n",
    "# This time let's use sklearn.metrics\n",
    "from sklearn import metrics\n",
    "n_cvbasic = yhat.size\n",
    "p_cvbasic = fmla_cvbasic.coef_.size + fmla_cvbasic.intercept_.size\n",
    "R2_cvbasic = metrics.r2_score(y_test, yhat)\n",
    "MSE_cvbasic = metrics.mean_squared_error(y_test, yhat)\n",
    "\n",
    "print(\"Regression on basic model using cross validation: p=%.0f, R2=%.2f, MSE=%.2f\" %(p_cvbasic, R2_cvbasic, MSE_cvbasic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using cross correlation\n",
    "### Flexible model with 33 features: linear and quadratic specifications plus their two-way interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression on flexible model using cross validation: p=47, R2=0.07, MSE=191.91\n"
     ]
    }
   ],
   "source": [
    "###  Linear and Quadratic specifications plus their two-way interactions\n",
    "xint_train, xint_test, y_train, y_test = train_test_split(xint, y, test_size=0.8, random_state=0)\n",
    "\n",
    "fmla_cvflex = LinearRegression(fit_intercept=True)\n",
    "fmla_cvflex.fit(xint_train,y_train)\n",
    "yhat_cvflex = fmla_cvflex.predict(xint_test)\n",
    "\n",
    "n_cvflex = yhat_cvflex.size\n",
    "p_cvflex = fmla_cvflex.coef_.size + fmla_cvflex.intercept_.size\n",
    "R2_cvflex = metrics.r2_score(y_test, yhat_cvflex)\n",
    "MSE_cvflex = metrics.mean_squared_error(y_test, yhat_cvflex)\n",
    "\n",
    "print(\"Regression on flexible model using cross validation: p=%.0f, R2=%.2f, MSE=%.2f\" %(p_cvflex, R2_cvflex, MSE_cvflex))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression on basic model using cross validation: p=11, R2=0.08, MSE=189.35\n",
      "Regression on flexible model using cross validation: p=47, R2=0.07, MSE=191.91\n"
     ]
    }
   ],
   "source": [
    "print(\"Regression on basic model using cross validation: p=%.0f, R2=%.2f, MSE=%.2f\" %(p_cvbasic, R2_cvbasic, MSE_cvbasic))\n",
    "print(\"Regression on flexible model using cross validation: p=%.0f, R2=%.2f, MSE=%.2f\" %(p_cvflex, R2_cvflex, MSE_cvflex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using patsy and statsmodels\n",
    "[Patsy](https://patsy.readthedocs.io/en/latest/#): describing statistical models in Python using symbolic formulas\n",
    "\n",
    "Use pip to install patsy:\n",
    "\n",
    "`sudo pip install -U patsy`\n",
    "\n",
    "`sudo pip install -U statsmodels`\n",
    "\n",
    "Otherwise see [here](https://patsy.readthedocs.io/en/latest/overview.html#download) to download the source patsy-0.4.1.zip and installed it using: \n",
    "\n",
    "`sudo python setup.py install`\n",
    "\n",
    "I installed statsmodel with: \n",
    "\n",
    "`sudo python -mpip install statsmodels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Basic model with 10 features\n",
    "###  Linear and Quadratic specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>wage</td>       <th>  R-squared:         </th> <td>   0.095</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.093</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   44.87</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 29 Sep 2017</td> <th>  Prob (F-statistic):</th> <td>3.17e-77</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:16:13</td>     <th>  Log-Likelihood:    </th> <td> -15235.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  3835</td>      <th>  AIC:               </th> <td>3.049e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  3825</td>      <th>  BIC:               </th> <td>3.055e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    4.9154</td> <td>    1.299</td> <td>    3.784</td> <td> 0.000</td> <td>    2.368</td> <td>    7.462</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>female</th>    <td>   -1.8264</td> <td>    0.425</td> <td>   -4.302</td> <td> 0.000</td> <td>   -2.659</td> <td>   -0.994</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sc</th>        <td>    2.4865</td> <td>    0.534</td> <td>    4.654</td> <td> 0.000</td> <td>    1.439</td> <td>    3.534</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cg</th>        <td>    9.8708</td> <td>    0.562</td> <td>   17.567</td> <td> 0.000</td> <td>    8.769</td> <td>   10.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mw</th>        <td>   -1.2142</td> <td>    0.566</td> <td>   -2.146</td> <td> 0.032</td> <td>   -2.323</td> <td>   -0.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>so</th>        <td>    0.4046</td> <td>    0.588</td> <td>    0.688</td> <td> 0.491</td> <td>   -0.748</td> <td>    1.558</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>we</th>        <td>   -0.2508</td> <td>    0.611</td> <td>   -0.410</td> <td> 0.682</td> <td>   -1.449</td> <td>    0.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exp1</th>      <td>    1.0965</td> <td>    0.269</td> <td>    4.077</td> <td> 0.000</td> <td>    0.569</td> <td>    1.624</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exp2</th>      <td>   -4.0134</td> <td>    1.785</td> <td>   -2.248</td> <td> 0.025</td> <td>   -7.514</td> <td>   -0.513</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exp3</th>      <td>    0.4603</td> <td>    0.344</td> <td>    1.340</td> <td> 0.180</td> <td>   -0.213</td> <td>    1.134</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>6626.018</td> <th>  Durbin-Watson:     </th>  <td>   1.958</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>8721375.158</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>11.808</td>  <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>235.426</td> <th>  Cond. No.          </th>  <td>    198.</td>  \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   wage   R-squared:                       0.095\n",
       "Model:                            OLS   Adj. R-squared:                  0.093\n",
       "Method:                 Least Squares   F-statistic:                     44.87\n",
       "Date:                Fri, 29 Sep 2017   Prob (F-statistic):           3.17e-77\n",
       "Time:                        18:16:13   Log-Likelihood:                -15235.\n",
       "No. Observations:                3835   AIC:                         3.049e+04\n",
       "Df Residuals:                    3825   BIC:                         3.055e+04\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      4.9154      1.299      3.784      0.000       2.368       7.462\n",
       "female        -1.8264      0.425     -4.302      0.000      -2.659      -0.994\n",
       "sc             2.4865      0.534      4.654      0.000       1.439       3.534\n",
       "cg             9.8708      0.562     17.567      0.000       8.769      10.972\n",
       "mw            -1.2142      0.566     -2.146      0.032      -2.323      -0.105\n",
       "so             0.4046      0.588      0.688      0.491      -0.748       1.558\n",
       "we            -0.2508      0.611     -0.410      0.682      -1.449       0.947\n",
       "exp1           1.0965      0.269      4.077      0.000       0.569       1.624\n",
       "exp2          -4.0134      1.785     -2.248      0.025      -7.514      -0.513\n",
       "exp3           0.4603      0.344      1.340      0.180      -0.213       1.134\n",
       "==============================================================================\n",
       "Omnibus:                     6626.018   Durbin-Watson:                   1.958\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          8721375.158\n",
       "Skew:                          11.808   Prob(JB):                         0.00\n",
       "Kurtosis:                     235.426   Cond. No.                         198.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.discrete.discrete_model as sm\n",
    "from patsy import dmatrices\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "data = pd.read_csv('data.csv', index_col=False, header=0)\n",
    "y, X = dmatrices(\"wage ~ female + sc+ cg+ mw + so + we + exp1 + exp2 + exp3\", \n",
    "                 data, return_type = 'dataframe')\n",
    "fit_basic = sm.OLS(y, X)\n",
    "result_basic = fit_basic.fit()\n",
    "yhat_basic = result_basic.predict(X)\n",
    "result_basic.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flexible model with 33 features \n",
    "### Linear and Quadratic specifications plus their two-way interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>wage</td>       <th>  R-squared:         </th> <td>   0.104</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.096</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   13.79</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 29 Sep 2017</td> <th>  Prob (F-statistic):</th> <td>5.53e-69</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:16:13</td>     <th>  Log-Likelihood:    </th> <td> -15217.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  3835</td>      <th>  AIC:               </th> <td>3.050e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  3802</td>      <th>  BIC:               </th> <td>3.071e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    32</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   16.5524</td> <td>    7.175</td> <td>    2.307</td> <td> 0.021</td> <td>    2.486</td> <td>   30.619</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>female</th>    <td>   -1.8800</td> <td>    0.425</td> <td>   -4.426</td> <td> 0.000</td> <td>   -2.713</td> <td>   -1.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sc</th>        <td>   -2.3865</td> <td>    5.415</td> <td>   -0.441</td> <td> 0.659</td> <td>  -13.003</td> <td>    8.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cg</th>        <td>    2.2405</td> <td>    5.908</td> <td>    0.379</td> <td> 0.705</td> <td>   -9.342</td> <td>   13.823</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mw</th>        <td>   -5.5194</td> <td>    3.375</td> <td>   -1.635</td> <td> 0.102</td> <td>  -12.137</td> <td>    1.098</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>so</th>        <td>   -2.9144</td> <td>    3.482</td> <td>   -0.837</td> <td> 0.403</td> <td>   -9.742</td> <td>    3.913</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>we</th>        <td>   -0.8054</td> <td>    3.646</td> <td>   -0.221</td> <td> 0.825</td> <td>   -7.953</td> <td>    6.342</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exp1</th>      <td>   -1.3215</td> <td>    2.073</td> <td>   -0.638</td> <td> 0.524</td> <td>   -5.386</td> <td>    2.743</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exp2</th>      <td>   12.5218</td> <td>   24.780</td> <td>    0.505</td> <td> 0.613</td> <td>  -36.062</td> <td>   61.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exp3</th>      <td>   -0.0484</td> <td>    0.151</td> <td>   -0.321</td> <td> 0.748</td> <td>   -0.344</td> <td>    0.247</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sc:cg</th>     <td> 1.071e-13</td> <td> 2.53e-13</td> <td>    0.424</td> <td> 0.672</td> <td>-3.88e-13</td> <td> 6.02e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sc:mw</th>     <td>   -0.7226</td> <td>    1.445</td> <td>   -0.500</td> <td> 0.617</td> <td>   -3.555</td> <td>    2.110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sc:so</th>     <td>   -0.6513</td> <td>    1.534</td> <td>   -0.424</td> <td> 0.671</td> <td>   -3.659</td> <td>    2.357</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sc:we</th>     <td>   -0.1047</td> <td>    1.592</td> <td>   -0.066</td> <td> 0.948</td> <td>   -3.227</td> <td>    3.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sc:exp1</th>   <td>    0.8391</td> <td>    1.097</td> <td>    0.765</td> <td> 0.444</td> <td>   -1.311</td> <td>    2.989</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sc:exp2</th>   <td>   -4.0608</td> <td>    6.512</td> <td>   -0.624</td> <td> 0.533</td> <td>  -16.827</td> <td>    8.706</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sc:exp3</th>   <td>    0.6330</td> <td>    1.158</td> <td>    0.547</td> <td> 0.585</td> <td>   -1.637</td> <td>    2.904</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cg:mw</th>     <td>   -0.7609</td> <td>    1.536</td> <td>   -0.496</td> <td> 0.620</td> <td>   -3.772</td> <td>    2.250</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cg:so</th>     <td>    1.7041</td> <td>    1.569</td> <td>    1.086</td> <td> 0.278</td> <td>   -1.373</td> <td>    4.781</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cg:we</th>     <td>   -1.4948</td> <td>    1.637</td> <td>   -0.913</td> <td> 0.361</td> <td>   -4.704</td> <td>    1.715</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cg:exp1</th>   <td>    0.7859</td> <td>    1.245</td> <td>    0.631</td> <td> 0.528</td> <td>   -1.654</td> <td>    3.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cg:exp2</th>   <td>   -0.0490</td> <td>    7.761</td> <td>   -0.006</td> <td> 0.995</td> <td>  -15.265</td> <td>   15.167</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cg:exp3</th>   <td>   -0.5950</td> <td>    1.462</td> <td>   -0.407</td> <td> 0.684</td> <td>   -3.462</td> <td>    2.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mw:so</th>     <td>-4.324e-16</td> <td> 5.34e-15</td> <td>   -0.081</td> <td> 0.935</td> <td>-1.09e-14</td> <td>    1e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mw:we</th>     <td> 8.422e-15</td> <td> 1.63e-14</td> <td>    0.517</td> <td> 0.605</td> <td>-2.35e-14</td> <td> 4.04e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mw:exp1</th>   <td>    1.1076</td> <td>    0.724</td> <td>    1.530</td> <td> 0.126</td> <td>   -0.312</td> <td>    2.527</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mw:exp2</th>   <td>   -6.0527</td> <td>    4.790</td> <td>   -1.264</td> <td> 0.206</td> <td>  -15.444</td> <td>    3.339</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mw:exp3</th>   <td>    0.9063</td> <td>    0.919</td> <td>    0.987</td> <td> 0.324</td> <td>   -0.895</td> <td>    2.707</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>so:we</th>     <td>-7.975e-15</td> <td>  1.5e-14</td> <td>   -0.532</td> <td> 0.595</td> <td>-3.74e-14</td> <td> 2.14e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>so:exp1</th>   <td>    0.3947</td> <td>    0.748</td> <td>    0.528</td> <td> 0.598</td> <td>   -1.072</td> <td>    1.861</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>so:exp2</th>   <td>   -0.8914</td> <td>    4.973</td> <td>   -0.179</td> <td> 0.858</td> <td>  -10.641</td> <td>    8.858</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>so:exp3</th>   <td>   -0.0352</td> <td>    0.960</td> <td>   -0.037</td> <td> 0.971</td> <td>   -1.917</td> <td>    1.847</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>we:exp1</th>   <td>    0.4719</td> <td>    0.790</td> <td>    0.597</td> <td> 0.550</td> <td>   -1.077</td> <td>    2.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>we:exp2</th>   <td>   -3.9188</td> <td>    5.300</td> <td>   -0.739</td> <td> 0.460</td> <td>  -14.309</td> <td>    6.472</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>we:exp3</th>   <td>    0.8050</td> <td>    1.034</td> <td>    0.778</td> <td> 0.436</td> <td>   -1.223</td> <td>    2.833</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exp1:exp2</th> <td>   -0.4839</td> <td>    1.505</td> <td>   -0.321</td> <td> 0.748</td> <td>   -3.435</td> <td>    2.467</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exp1:exp3</th> <td>    0.0872</td> <td>    0.451</td> <td>    0.193</td> <td> 0.847</td> <td>   -0.797</td> <td>    0.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exp2:exp3</th> <td>   -0.0580</td> <td>    0.503</td> <td>   -0.115</td> <td> 0.908</td> <td>   -1.044</td> <td>    0.928</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>6588.420</td> <th>  Durbin-Watson:     </th>  <td>   1.959</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>8473264.498</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>11.669</td>  <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>232.090</td> <th>  Cond. No.          </th>  <td>1.14e+16</td>  \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   wage   R-squared:                       0.104\n",
       "Model:                            OLS   Adj. R-squared:                  0.096\n",
       "Method:                 Least Squares   F-statistic:                     13.79\n",
       "Date:                Fri, 29 Sep 2017   Prob (F-statistic):           5.53e-69\n",
       "Time:                        18:16:13   Log-Likelihood:                -15217.\n",
       "No. Observations:                3835   AIC:                         3.050e+04\n",
       "Df Residuals:                    3802   BIC:                         3.071e+04\n",
       "Df Model:                          32                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     16.5524      7.175      2.307      0.021       2.486      30.619\n",
       "female        -1.8800      0.425     -4.426      0.000      -2.713      -1.047\n",
       "sc            -2.3865      5.415     -0.441      0.659     -13.003       8.230\n",
       "cg             2.2405      5.908      0.379      0.705      -9.342      13.823\n",
       "mw            -5.5194      3.375     -1.635      0.102     -12.137       1.098\n",
       "so            -2.9144      3.482     -0.837      0.403      -9.742       3.913\n",
       "we            -0.8054      3.646     -0.221      0.825      -7.953       6.342\n",
       "exp1          -1.3215      2.073     -0.638      0.524      -5.386       2.743\n",
       "exp2          12.5218     24.780      0.505      0.613     -36.062      61.106\n",
       "exp3          -0.0484      0.151     -0.321      0.748      -0.344       0.247\n",
       "sc:cg       1.071e-13   2.53e-13      0.424      0.672   -3.88e-13    6.02e-13\n",
       "sc:mw         -0.7226      1.445     -0.500      0.617      -3.555       2.110\n",
       "sc:so         -0.6513      1.534     -0.424      0.671      -3.659       2.357\n",
       "sc:we         -0.1047      1.592     -0.066      0.948      -3.227       3.018\n",
       "sc:exp1        0.8391      1.097      0.765      0.444      -1.311       2.989\n",
       "sc:exp2       -4.0608      6.512     -0.624      0.533     -16.827       8.706\n",
       "sc:exp3        0.6330      1.158      0.547      0.585      -1.637       2.904\n",
       "cg:mw         -0.7609      1.536     -0.496      0.620      -3.772       2.250\n",
       "cg:so          1.7041      1.569      1.086      0.278      -1.373       4.781\n",
       "cg:we         -1.4948      1.637     -0.913      0.361      -4.704       1.715\n",
       "cg:exp1        0.7859      1.245      0.631      0.528      -1.654       3.226\n",
       "cg:exp2       -0.0490      7.761     -0.006      0.995     -15.265      15.167\n",
       "cg:exp3       -0.5950      1.462     -0.407      0.684      -3.462       2.272\n",
       "mw:so      -4.324e-16   5.34e-15     -0.081      0.935   -1.09e-14       1e-14\n",
       "mw:we       8.422e-15   1.63e-14      0.517      0.605   -2.35e-14    4.04e-14\n",
       "mw:exp1        1.1076      0.724      1.530      0.126      -0.312       2.527\n",
       "mw:exp2       -6.0527      4.790     -1.264      0.206     -15.444       3.339\n",
       "mw:exp3        0.9063      0.919      0.987      0.324      -0.895       2.707\n",
       "so:we      -7.975e-15    1.5e-14     -0.532      0.595   -3.74e-14    2.14e-14\n",
       "so:exp1        0.3947      0.748      0.528      0.598      -1.072       1.861\n",
       "so:exp2       -0.8914      4.973     -0.179      0.858     -10.641       8.858\n",
       "so:exp3       -0.0352      0.960     -0.037      0.971      -1.917       1.847\n",
       "we:exp1        0.4719      0.790      0.597      0.550      -1.077       2.021\n",
       "we:exp2       -3.9188      5.300     -0.739      0.460     -14.309       6.472\n",
       "we:exp3        0.8050      1.034      0.778      0.436      -1.223       2.833\n",
       "exp1:exp2     -0.4839      1.505     -0.321      0.748      -3.435       2.467\n",
       "exp1:exp3      0.0872      0.451      0.193      0.847      -0.797       0.972\n",
       "exp2:exp3     -0.0580      0.503     -0.115      0.908      -1.044       0.928\n",
       "==============================================================================\n",
       "Omnibus:                     6588.420   Durbin-Watson:                   1.959\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          8473264.498\n",
       "Skew:                          11.669   Prob(JB):                         0.00\n",
       "Kurtosis:                     232.090   Cond. No.                     1.14e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 3.61e-24. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_flex, X_flex = dmatrices(\"wage ~  female + (sc+ cg+ mw + so + we + exp1 + exp2 + exp3)**2\", \n",
    "                 data, return_type = 'dataframe')\n",
    "fit_flex = sm.OLS(y_flex, X_flex)\n",
    "result_flex = fit_flex.fit()\n",
    "yhat_flex = result_flex.predict(X_flex)\n",
    "result_flex.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using patsy and statsmodels\n",
      "Regression on basic model: p=10, R2=0.10, MSE=165.25\n",
      "Regression on flexible model: p=33, R2=0.10, MSE=163.70\n"
     ]
    }
   ],
   "source": [
    "# Let's use sklearn metrics to summarize\n",
    "from sklearn import metrics\n",
    "MSE_basic = metrics.mean_squared_error(y.wage.values, yhat_basic)\n",
    "R2_basic = metrics.r2_score(y.wage.values, yhat_basic)\n",
    "print(\"Using patsy and statsmodels\")\n",
    "print(\"Regression on basic model: p=%.0f, R2=%.2f, MSE=%.2f\" %(10, R2_basic, MSE_basic))\n",
    "\n",
    "MSE_flex = metrics.mean_squared_error(y_flex.wage.values, yhat_flex)\n",
    "R2_flex = metrics.r2_score(y_flex.wage.values, yhat_flex)\n",
    "print(\"Regression on flexible model: p=%.0f, R2=%.2f, MSE=%.2f\" %(33, R2_flex, MSE_flex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using cross correlation\n",
    "### Basic model with 10 features: linear and quadratic specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((767, 12), (767, 12))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Use cross validation on the data\n",
    "from sklearn.cross_validation import train_test_split\n",
    "data_train, data_test = train_test_split(data,  test_size=0.8, random_state=0)\n",
    "data_train.shape,data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trainbasic, X_trainbasic = dmatrices(\"wage ~ female + sc+ cg+ mw + so + we + exp1 + exp2 + exp3\", \n",
    "                 data_train, return_type = 'dataframe')\n",
    "y_testbasic, X_testbasic = dmatrices(\"wage ~ female + sc+ cg+ mw + so + we + exp1 + exp2 + exp3\", \n",
    "                 data_test, return_type = 'dataframe')\n",
    "fit_cvbasic = sm.OLS(y_trainbasic, X_trainbasic)\n",
    "result_cvbasic = fit_cvbasic.fit()\n",
    "yhat_cvbasic = result_cvbasic.predict(X_testbasic)\n",
    "#result_cvbasic.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using cross correlation\n",
    "### Flexible model with 33 features: linear and quadratic specifications plus their two-way interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trainflex, X_trainflex = dmatrices(\"wage ~  female + (sc+ cg+ mw + so + we + exp1 + exp2 + exp3)**2\", \n",
    "                 data_train, return_type = 'dataframe')\n",
    "y_testflex, X_testflex = dmatrices(\"wage ~  female + (sc+ cg+ mw + so + we + exp1 + exp2 + exp3)**2\", \n",
    "                 data_train, return_type = 'dataframe')\n",
    "fit_cvflex = sm.OLS(y_trainflex, X_trainflex)\n",
    "result_cvflex = fit_cvflex.fit()\n",
    "yhat_cvflex = result_cvflex.predict(X_testflex)\n",
    "result_cvflex.summary();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using patsy and statsmodels\n",
      "Regression on basic model using cross validation: p=10, R2=0.08, MSE=189.35\n",
      "Regression on flexible model using cross validation: p=47, R2=0.15, MSE=75.50\n",
      "uh? did I mess up the last one? oh well..\n"
     ]
    }
   ],
   "source": [
    "# Let's use sklearn metrics to summarize\n",
    "MSE_cvbasic = metrics.mean_squared_error(y_testbasic.wage.values, yhat_cvbasic)\n",
    "R2_cvbasic = metrics.r2_score(y_testbasic.wage.values, yhat_cvbasic)\n",
    "print(\"Using patsy and statsmodels\")\n",
    "print(\"Regression on basic model using cross validation: p=%.0f, R2=%.2f, MSE=%.2f\" %(10, R2_cvbasic, MSE_cvbasic))\n",
    "\n",
    "MSE_cvflex = metrics.mean_squared_error(y_testflex.wage.values, yhat_cvflex)\n",
    "R2_cvflex = metrics.r2_score(y_testflex.wage.values, yhat_cvflex)\n",
    "print(\"Regression on flexible model using cross validation: p=%.0f, R2=%.2f, MSE=%.2f\" %(47, R2_cvflex, MSE_cvflex))\n",
    "\n",
    "print(\"uh? did I mess up the last one? oh well..\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
